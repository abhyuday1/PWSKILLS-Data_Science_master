{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc46065e",
   "metadata": {},
   "source": [
    "## Q1. What is the KNN algorithm?\n",
    "\n",
    "THe K-Nearest neighbor algorithm is used for both classfication and regression tasks.\n",
    "\n",
    "-it classifies new data points based on the similarities to their nearest neighbors in the training data.\n",
    "\n",
    "-Nearest is defined by a distance metric like Euclidean or Manhatten distance.\n",
    "\n",
    "-In Regression it predicts the value of the new data point by averaging the vaues of its k-nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4443f4",
   "metadata": {},
   "source": [
    "##  Q2. How do you choose the value of K in KNN?\n",
    "\n",
    "--The Optimal K depends on the specific Data and problem.\n",
    "\n",
    "--Small K can capture local details but can be sensitive to noise and leads to overfitting.\n",
    "\n",
    "--Large K can ignores local details and leads to smoother descision boundries, BUt can suffer from underfitting.\n",
    "\n",
    "\n",
    "Methods for choosing K:\n",
    "1. Cross Vaidation:- Divide Data into folds , train model on each fold with different k values and evalute its performance on hte remaining folds.\n",
    "\n",
    "2. Domain Knowledge:-Expertise in the problem domain, it can help to decide K.\n",
    "\n",
    "--The Choice of distance metric can also influence the optimal k.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d2192f",
   "metadata": {},
   "source": [
    "##  Q3. What is the difference between KNN classifier and KNN regressor?\n",
    "\n",
    "\n",
    "### Difference:-\n",
    "\n",
    "1. Target Varaible:- In Classifier the target Variable is Categorical whereas in Regressor Target Variable is Continuous variable.\n",
    "\n",
    "2. Prediction:- In Classfier the new data point is assigned to the most frequest class among its k nearest neighbor.\n",
    "\n",
    "3. Evaluation:- Claasifer evaluation metrics are Accuracy, Precision, recall, F1-score.\n",
    "\n",
    "Regresssor Evalution metrics are MSE, R-Squared, RMSE.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1131f3f9",
   "metadata": {},
   "source": [
    "##  Q4. How do you measure the performance of KNN?\n",
    "\n",
    "It depends on the problem wheter it is Classification problem or Reggression problem.\n",
    "\n",
    "FOr Claasification:-\n",
    "    1. Accuracy\n",
    "    2.Recall\n",
    "    3.F1-score\n",
    "    4.Precision\n",
    "    5. Confusion matrix\n",
    "    Area under the ROC CURVE(AUC)\n",
    "For Regression:-\n",
    "    1. RMSE\n",
    "    2. MSE\n",
    "    3. R-squared\n",
    "    4. Mean Absolute Error\n",
    "    5.Adjusted R-Squared\n",
    "\n",
    "--IT also depends on the Data size , problem Domain, Computaional Complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a13053",
   "metadata": {},
   "source": [
    "## Q5. What is the curse of dimensionality in KNN?\n",
    "\n",
    "The curse of dimensionality refers to the phenomenon where the performance of KNN algorithm degreds significantly as the dimensionality of the feature increases.As the  features increases, the volume of space increaces exponentially.\n",
    "\n",
    "-- As a result in high dimensional space the nearest neighbors of a point may not be very close to it in teerms of actual similarity, leading to potentially inaccurate classifications or prediction.\n",
    "\n",
    "--To mitigate the curse of dimensionality in KNN, techniques such as dimensionality reduction (PCA) or feature selection cvan be employed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c12a9a",
   "metadata": {},
   "source": [
    "## Q6. How do you handle missing values in KNN?\n",
    "Handling missing values in KNN can be approached in several ways:\n",
    "\n",
    "1. Imputaion:- one common approach is to impute missing values with some estimated or calculated values.\n",
    "\n",
    "2. Ignore missing values:- Another approcah is simply ignore instances with the missing vaues during the distance computation.\n",
    "\n",
    "3. Data imputation before applying KNNN\n",
    "\n",
    "4. Use algorithm robust to missing values:- instead of using KNN, we can use algorithm that are inherently robust to missing values, such as decision trees or random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f99d65",
   "metadata": {},
   "source": [
    "## Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem? \n",
    "\n",
    "Both KNN classifier and Regressor are supervised learning algorithm, but they are used for different types of problems and have different characteristics.\n",
    "\n",
    "1. KNN classifier is for the classification tasks where goal is to predict the class label of a new instance, where as KNN regressor is used for regression task where the goal is to predict a continueous target variable baased on the values of the predictor variable.\n",
    "\n",
    "2. The performance of the both classifier and regressor depends on the facors such as the choice of distance metric, number of k, dimensionality etc.\n",
    "\n",
    "3. KNN regressor may be more sensitive to outliers and noisy data compared to classifer, as it relies on the numerical vaues of the target variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18d4ee",
   "metadata": {},
   "source": [
    "## Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed? \n",
    "\n",
    "### Strengths:-\n",
    "\n",
    "1. simple to understand and implement\n",
    "2. Non Parameteic means it does not make any assumptions about underlying data distribution.\n",
    "3. Adaptability to complex decision boundries sinsce it does not make assumptions about the shape of the decison boundry.\n",
    "\n",
    "### Weakness:-\n",
    "1. Computational Complexity especially for large datasets, because it requires calculating the distance between the query instance ans all training instances for each prediction.\n",
    "\n",
    "2. sensitive to irrelevent features\n",
    "\n",
    "3. Need for optimal value of K.\n",
    "4. imbalanced data handling.\n",
    "\n",
    "### Addressing weakness:-\n",
    "1. Dimensionality reduction like PCA or feature selection to reduce the dimensionality of the feature space.\n",
    "\n",
    "2. Feature engineering.\n",
    "\n",
    "3. Ensemble Methods:- combine multiple KNN models with different k values to improve predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb87f9",
   "metadata": {},
   "source": [
    "## Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?\n",
    "\n",
    "The main differnece between them lies in how they compute the distacne between two points in a multidimentional space.\n",
    "\n",
    "1. Euclidean Distance:-\n",
    "Calculates the distance between two points in a straigth line, considering the square root of the sum of squared difference between corresponding coordinates.\n",
    "\n",
    "2. Manhattan Distance:-\n",
    "It calculates the distance between two points as the sum of the absolute difference between corresponding coordinates.\n",
    "\n",
    "-- Manhattan is less sensitive to outliers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce062835",
   "metadata": {},
   "source": [
    "## 10. What is the role of feature scaling in KNN? \n",
    "The main role of feature scalling in KNN are as follows:-\n",
    "\n",
    "1. Equal weightage of Features\n",
    "2. Improved Model Performance\n",
    "3.Better Handling of Distance- Based Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359fc372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
