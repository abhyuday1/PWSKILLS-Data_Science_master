{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd704503",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "\n",
    "- SImple and multiple Linear Regression are both used in Statistics to model the relationship between independent and dependent variable but they differ in terms of number of independent variable.\n",
    "\n",
    "--Simple Linear REgression\n",
    "--\n",
    "It is used when there is a single independent variable that is used to predict a continuous dependent variable.\n",
    "\n",
    "Example:-\n",
    "\n",
    "Consider we want to predict a person's salary based on the number of years of experience. in this case we have to use simple linear regression. as it has only one independent variable.\n",
    "\n",
    "and Regression equation will be:-\n",
    "salary=H(0)+H(1)* years of experience\n",
    "\n",
    "--Multiple Linear Regression\n",
    "--\n",
    " it is used when there are two or more independent variables that are used to predict a continuous dependent variable.\n",
    " \n",
    " \n",
    " Consider  we want to predict the price of a house based on independent variables like number of bedroooms, distance to the city etc. in this case we have to use multiple linear regression.\n",
    " \n",
    " and regression equation will be:-\n",
    " Price=H(0)+H(1)*Number of bedrooms+H(2)* distance to city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb620a",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "\n",
    "1. Linearity:-\n",
    "The relationshipt between independent and dependent variable is assumed to be linear.\n",
    "\n",
    "2. Independence of Errors:-\n",
    "The errors should be independent to each other means the value error for one data point not be related to the value error for another data point.\n",
    "\n",
    "3. No or Little Multicollinearity:-\n",
    "Multicollinearity occurs when independent variables are highly correlated to each other.\n",
    "\n",
    "4. No Outliers:-\n",
    "Outliers are data point that deviate significantly fro the rest of the data.\n",
    "\n",
    "--TO check whether these assumptions hold in the dataset, we can follow these steps:-\n",
    "1. Visual inspection:-\n",
    "we can create differnts plots of the data to visually assess .\n",
    "\n",
    "2. Statistical tests:-\n",
    "we can use formal statistical tests to quantitavely assess the assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec723d77",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "\n",
    "\n",
    "Intercept :- The intercept represents the value of the dependent variable when all independent variables are equal to zero. It is the value of the dependent variable when there is no influence of the independent variables.\n",
    "\n",
    "Slope : The slope represent the change in the dependent variable for a one-unit change in the corresponding independent variable, holding all other independent variables constant.\n",
    "\n",
    "for example:-\n",
    "consider we are studying the relationship between the number of hours a student spends studying and their final exam score\n",
    "\n",
    "Regression equation:-\n",
    "Exam score=H(0)+H(1)* Hours of study\n",
    "\n",
    "Intercept(H0)=If the value of \"Hours of Study\" is zero  the intercept represents the expected exam score.\n",
    "\n",
    "Slope (H1): The slope represents the change in the expected exam score for a one-hour increase in the amount of time a student spends studying, while holding all other factors constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3fbff3",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "Gradient descent is an optimization algorithm used in machine learning and deep learning to minimize a cost function or loss function. It's a fundamental technique for training models and finding the optimal parameters that make a machine learning model perform well.\n",
    "\n",
    "--Gradient Descent Process:\n",
    "--\n",
    "- Gradient descent starts with an initial guess for the model's parameters.\n",
    "- It iteratively updates the parameters in the direction that minimizes the error by using the gradient (derivative) of the error with respect to the parameters.\n",
    "- The gradient represents the direction of the steepest increase in the error. By moving in the opposite direction of the gradient, the algorithm seeks to reach the minimum error, which corresponds to the optimal parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20e16d",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "- Multiple Linear Regression is an extension of the simple linear regression model. In simple linear regression, we have a single independent variable (predictor) that is used to predict a continuous dependent variable, while in multiple linear regression, we have two or more independent variables that are used to predict the same dependent variable.\n",
    "\n",
    "Differences from Simple Linear Regression:\n",
    "\n",
    "1. Number of Independent Variables:\n",
    "\n",
    "- Simple Linear Regression: Uses a single independent variable (X) to predict the dependent variable (Y).\n",
    "\n",
    "- Multiple Linear Regression: Uses two or more independent variables (X1, X2, X3, etc.) to predict the dependent variable (Y).\n",
    "\n",
    "2. Equation Complexity:\n",
    "\n",
    "- Simple Linear Regression: The regression equation is simpler with just one predictor, Y = H0 + H1 * X.\n",
    "\n",
    "- Multiple Linear Regression: The regression equation becomes more complex with multiple predictors, Y = H0 + H1 * X1 + H2 * X2 + ... + Hn * Xn.\n",
    "\n",
    "3. Interpretation:\n",
    "\n",
    "- In simple linear regression, the interpretation of the slope coefficient (Î²1) is straightforward as it represents the change in Y for a one-unit change in X.\n",
    "\n",
    "- In multiple linear regression, the interpretation of each coefficient becomes more nuanced, as the effect of one independent variable on the dependent variable depends on the values of all the other independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322bc411",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "\n",
    "- Multicollinearity is a common issue in multiple linear regression when two or more independent variables in a model are highly correlated with each other. This correlation can make it challenging to separate the individual effects of these variables on the dependent variable. \n",
    "\n",
    "-- Detection\n",
    "--\n",
    "\n",
    "- Correlation Matrix:-Calculate the correlation matrix for the independent variables. High absolute correlation values (close to 1 or -1) between pairs of variables indicate potential multicollinearity.\n",
    "\n",
    "-- Addressing\n",
    "--\n",
    "1. Remove or Combine Variables\n",
    "2. Feature Selection Techniques\n",
    "3. Pricipal Component Analysis\n",
    "4. Collect More Data\n",
    "5. Data Transformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88192080",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "- Polynomial regression is a type of regression analysis used when the relationship between the independent variable and the dependent variable cannot be adequately modeled with a simple linear regression. In polynomial regression, we use a polynomial equation to describe this relationship.\n",
    "\n",
    "-- Linear Regression:\n",
    "--\n",
    "- In a linear regression model, the relationship between the dependent variable (Y) and the independent variable (X) is assumed to be linear. The regression equation takes the form:\n",
    "\n",
    "Y = H0 + H1 * X \n",
    "\n",
    "- In linear regression, the relationship is represented by a straight line, which is the simplest form of regression.\n",
    "\n",
    "-- Polynomial Regression:\n",
    "--\n",
    "- In polynomial regression, the relationship between the dependent variable and the independent variable is described by a polynomial equation. \n",
    "\n",
    "Y= H0 + H1*X + H2* X^2 + H3* X^3 +....\n",
    "\n",
    "-- Difference\n",
    "--\n",
    "1. Linearity\n",
    " Linear regression assumes a linear relationship between the independent and dependent variables, while polynomial regression allows for non-linear relationships.\n",
    " \n",
    "2. Equation Form: \n",
    " Linear regression has a simple linear equation, while polynomial regression has a more complex equation that includes higher-order terms of the independent variable.\n",
    " \n",
    "3. Interpretability: \n",
    " Linear regression models are often more interpretable, as they provide direct relationships between variables. Whereas polynomial regression models may be more challenging to interpret due to their complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04a776",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "--Advantages of Polynomial Regression:\n",
    "--\n",
    "1. Captures Non-Linear Patterns:\n",
    "Polynomial regression can model non-linear relationships between the independent and dependent variables, which linear regression cannot capture.\n",
    "\n",
    "2. Flexibility:\n",
    "It allows for more flexible curve fitting and can adapt to complex data patterns.\n",
    "\n",
    "-- Disadvantages of Polynomial Regression:\n",
    "--\n",
    "1. Overfitting:\n",
    "Polynomial regression is more susceptible to overfitting when the polynomial degree is too high. \n",
    "\n",
    "2. Complexity:\n",
    "The model can become very complex as the polynomial degree increases, making it harder to interpret and understand.\n",
    "\n",
    "--Situations Where Polynomial Regression Is Preferred:\n",
    "--\n",
    "1. Non-Linear Data:\n",
    "When the relationship between variables is non-linear, polynomial regression is a good choice to capture the underlying patterns.\n",
    "\n",
    "2. Complex Patterns:\n",
    "In cases where the data exhibits curvilinear patterns, polynomial regression can provide a more accurate fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b8d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
